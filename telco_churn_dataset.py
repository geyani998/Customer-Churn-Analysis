# -*- coding: utf-8 -*-
"""Telco Churn Dataset.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-4CEIZZPnNjQZXDymbBgd1uOFW_G6HMB
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import seaborn as sns
import matplotlib as plt
import matplotlib.pyplot as plt
# import matplotlib.ticker as mtick
path = "/content/drive/MyDrive/WA_Fn-UseC_-Telco-Customer-Churn.csv"
churn_data = pd.read_csv(path)

print(churn_data.head())

churn_data.info()

t = churn_data['Churn'].value_counts()
count_y = t[0]
count_n = t[1]
print(count_y,count_n)

"""From above we can see that data is imbalanced"""

churn_data.shape

churn_data.dtypes
# Most are categorical values

churn_data.isnull().sum()  #We conclude that there are no missing values

churn_data.describe()

import matplotlib.pyplot as plt
labels = ['Yes','No']
counts = [count_y,count_n]
plt.bar(labels, counts, color=['Red', 'Green'])

# Adding labels and title
plt.xlabel('Churned')
plt.ylabel('Counts')
plt.title('Churned Target Counts')

# Display the plot
plt.show()

print("Percentage of churned candidates: \n")
print("Yes Percentage:",round((count_y/(count_y+count_n))*100,2))
print("No Percentage:",round((count_n/(count_y+count_n))*100,2))

churn_data.TotalCharges = pd.to_numeric(churn_data.TotalCharges, errors='coerce')
churn_data.isnull().sum()

churn_data.loc[churn_data ['TotalCharges'].isnull() == True]

churn_data.dropna(how = 'any', inplace = True)

churn_data.loc[churn_data ['TotalCharges'].isnull() == True] #As there is no display of rows below, we have removed rows with TotalCharges value as Nan

"""Let us divide the tenure data into bins for easier understanding

"""

print(churn_data['tenure'].max())

labels = ["{0} - {1}".format(i, i + 11) for i in range(1, 72, 12)]

churn_data['tenure_group'] = pd.cut(churn_data.tenure, range(1, 80, 12), right=False, labels=labels)

churn_data['tenure_group'].value_counts()

columns_to_drop = ['tenure', 'customerID']
churn_data = churn_data.drop(columns=columns_to_drop)

churn_data.head()

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Categorical features
for col in churn_data.drop(columns = ['Churn','TotalCharges','MonthlyCharges']):
    plt.figure(figsize=(4, 3))
    sns.countplot(data=churn_data, x=col, hue='Churn')
    plt.title(f'{col} vs Churn')
    plt.xticks(rotation=45)
    plt.show()

# Insights through univariate analysis:
# -Senior Citizens are less likely to churn,hence if the company retains customers upto a certain age, they will get loyal customers
# -Gender has nothing to do with churning as equal percentage of men and women churned
# -Obviously, the customers who do not have phone service have high churn percentage
# -Customers who do not have multiple lines have churned more than the ones that have
# -The customers who do not have online security have high churn percentage
# -Customers who do not have Online backup have high churn percentage
# -The customers with no tech support have churned more
# -Customers who opted for month to month contracts have churned highly
# -Customers who often paid by electronic check have churned more
# -Customers in the 1-12 year tenure have churned more

"""Steps to retain more customers:

*   Persuade customers to take yearly or longer contracts, month-to-month contract customers are highly likely to churn
*   Retain customers upto the lower range of senior citizens age, to have life long customers.
*   Offer online backup for low prices and also offer tech support, as customers without online backup and tech support often churned
*   Make your payment gateway secure, and reliable, people who often paid by electronic check have churned highly, obtain insights into why it is happening











"""

churn_data['Churn'] = (churn_data['Churn'] == 'Yes').astype(int)

churn_data.head()

churn_data_dummies = pd.get_dummies(churn_data)
churn_data_dummies.head()

"""We have performed one hot encoding through which, telco_data_dummies will contain the original data with categorical columns replaced by one-hot encoded binary columns, which can be used as input for machine learning models that require numerical input."""

#Area Chart for numerical features TotalCharges, and MonthlyCharges

plt.figure(figsize=(10, 6))
sns.histplot(data=churn_data_dummies, x='MonthlyCharges', hue='Churn', multiple='stack', kde=True)
plt.title('Distribution of Monthly Charges with respect to Churn')
plt.xlabel('Monthly Charges')
plt.ylabel('Frequency')
plt.legend(title='Churn', labels=['No', 'Yes'])
plt.show()

plt.figure(figsize=(10, 6))
sns.histplot(data=churn_data_dummies, x='TotalCharges', hue='Churn', multiple='stack', kde=True)
plt.title('Distribution of Total Charges with respect to Churn')
plt.xlabel('Total Charges')
plt.ylabel('Frequency')
plt.legend(title='Churn', labels=['No', 'Yes'])
plt.show()

"""*   Lower Total Charges is leading to higher churn(Unexpected)

*  But what's happening: Higher monthly charge at lower tenure results lower charge but higher churn percentage.

* **Solution**: Persuade customers to take longer contracts.

**Model Building**
"""

x = churn_data_dummies.drop('Churn',axis=1)
x

y = churn_data_dummies['Churn']
y

"""Train test split (80-20)"""

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

"""Decision Tree"""

from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(max_depth=6, min_samples_leaf=8, random_state=100)

dt.fit(x_train,y_train)

y_pred = dt.predict(x_test)

y_pred

from sklearn.metrics import accuracy_score
dt.score(x_test,y_test)

from sklearn.metrics import classification_report
print(classification_report(y_test, y_pred, labels=[0,1]))

"""Random Forest"""

from sklearn.ensemble import RandomForestClassifier

rf = RandomForestClassifier(n_estimators=100, criterion='gini', random_state = 100)

rf.fit(x_train,y_train)

y_pred = rf.predict(x_test)

rf.score(x_test,y_test)

print(classification_report(y_test,y_pred,labels=[0,1]))

"""Support Vector Machine"""

from sklearn.svm import SVC

svm = SVC(kernel= 'linear',C=1.0,random_state=42)

svm.fit(x_train,y_train)

y_pred = svm.predict(x_test)

print(svm.score(x_test,y_test))

print(classification_report(y_test,y_pred))

"""Logistic Regression"""

from sklearn.linear_model import LogisticRegression
lg = LogisticRegression()
lg.fit(x_train,y_train)

y_pred = lg.predict(x_test)

print(lg.score(x_test,y_test))

print(classification_report(y_test,y_pred))

"""As we can see for the above algorithms, the accuracy for class 1, i.e, the churned candidates is less, this is because the data is imbalanced, less number of samples for the case of 1's rather than zeroes.


Let us use SMOTE for upsampling
"""



"""Decision Tree(After Upsampling)"""

from imblearn.combine import SMOTEENN

sm = SMOTEENN()
x_resampled,y_resampled = sm.fit_resample(x,y)

xs_train,xs_test,ys_train,ys_test = train_test_split(x_resampled,y_resampled,test_size=0.2)

dt_smote = DecisionTreeClassifier(criterion = 'gini',random_state = 100,max_depth = 6)

dt_smote.fit(xs_train,ys_train)

ys_pred = dt_smote.predict(xs_test)

dt_smote.score(xs_test,ys_test)

print(classification_report(ys_test,ys_pred))

"""Random Forest(After Upsampling)"""

sm = SMOTEENN()
X_resampled1, y_resampled1 = sm.fit_resample(x,y)
xr_train1,xr_test1,yr_train1,yr_test1=train_test_split(X_resampled1, y_resampled1,test_size = 0.2)
model_rf_smote=RandomForestClassifier(n_estimators=100, criterion='gini', random_state = 100)
model_rf_smote.fit(xr_train1,yr_train1)

yr_predict1 = model_rf_smote.predict(xr_test1)
model_score_r1 = model_rf_smote.score(xr_test1, yr_test1)

print(model_score_r1)
print(classification_report(yr_test1, yr_predict1))

"""Logistic Regression(After Upsampling)"""

sm = SMOTEENN()
X_resampled2, y_resampled2 = sm.fit_resample(x,y)
xr_train2,xr_test2,yr_train2,yr_test2=train_test_split(X_resampled2, y_resampled2,test_size = 0.2)
lg_smote=LogisticRegression()
lg_smote.fit(xr_train2,yr_train2)

y_pred = lg_smote.predict(xr_test2)
print(lg_smote.score(xr_test2,yr_test2))

print(classification_report(yr_test2,y_pred))

import pickle

with open('customer_churn.pkl','wb') as file:
  pickle.dump(model_rf_smote,file)

pip install pycaret

from pycaret.datasets import get_data
from pycaret.classification import *

# Initialize PyCaret
setup(churn_data, target='Churn', session_id=123)

# Compare various models and evaluate their performance
compare_models()

